{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85291d4f",
   "metadata": {},
   "source": [
    "# Hypothesis\n",
    "\n",
    "Hypothesis: According to PBS News (https://www.pbs.org/newshour/politics/women-reflect-on-sexist-slur-that-often-goes-unpunished) the word \"Bitch\", which is considered a sexist slur is a word that often goes \"unpunished\". The word bitch also means female dog, but more often than not it is used in a derogatory context. If the word \"bitch\" is utilized in a comment, then it will be considered non-toxic more than toxic, because it is a word that has been decensitized and glossed over by society. \n",
    "\n",
    "From looking at the data, bitch in some contexts is not considered toxic, but when it is paired with other sexist slurs or other profanity such as \"fuck, it is considered toxic.\n",
    "\n",
    "For professional purposes, the word \"bitch\" will be reffered to as \"b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb521ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8464917",
   "metadata": {},
   "source": [
    "# Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e73b4b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Number of Comments labeled as 'Toxic' with the word 'Bitch' in it: 4\n",
      "Number of Comments labeled as 'non-Toxic' with the word 'Bitch' in it: 1\n"
     ]
    }
   ],
   "source": [
    "#Parsing through sample data set and choosing data points to establish threshold of average toxicity score\n",
    "\n",
    "sample_comments = pd.read_csv(\"Sample_labaled_data.csv\")\n",
    "# sample_comments.head()\n",
    "toxicity = list(sample_comments[\"toxic\"])\n",
    "comments = list(sample_comments[\"comment_text\"])\n",
    "\n",
    "toxic_comments = []\n",
    "neutral_comments = []\n",
    "\n",
    "for i in range(len(comments)):\n",
    "    toxic = toxicity[i]\n",
    "    comment = comments[i]\n",
    "    \n",
    "    if toxic == \"yes\":\n",
    "        toxic_comments.append(comment)\n",
    "    else:\n",
    "        neutral_comments.append(comment)\n",
    "        \n",
    "toxic_comments = toxic_comments[300:360]\n",
    "neutral_comments = neutral_comments[300:360]\n",
    "\n",
    "        \n",
    "# print(neutral_comments)\n",
    "print(\"done\")\n",
    "\n",
    "b_toxic_counter = 0\n",
    "for comment in toxic_comments:\n",
    "    if \"bitch\" in comment: \n",
    "        b_toxic_counter += 1\n",
    "        \n",
    "print(f\"Number of Comments labeled as 'Toxic' with the word 'Bitch' in it: {b_toxic_counter}\")\n",
    "\n",
    "b_neutral_counter = 0\n",
    "for comment in neutral_comments:\n",
    "    if \"bitch\" in comment: \n",
    "        b_neutral_counter += 1\n",
    "        \n",
    "print(f\"Number of Comments labeled as 'non-Toxic' with the word 'Bitch' in it: {b_neutral_counter}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10e96a",
   "metadata": {},
   "source": [
    "## Threshold and Fidnings for test data\n",
    "In this 60 comment data set, there is a 4:1 ratio of the word bitch being considered toxic versus not. This sample directly contradics my hypothesis but it is also taken from 30 data points. My bigger sample data which extracted all of the comments with the word \"Bitch\" and their label in it is around ~200 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5104bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 400 when requesting https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1&key=insert_api_key returned \"API key not valid. Please pass a valid API key.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'commentanalyzer.googleapis.com'}}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      4\u001b[0m API_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsert_api_key\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mdiscovery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommentanalyzer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv1alpha1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m \u001b[49m\u001b[43mdeveloperKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m \u001b[49m\u001b[43mdiscoveryServiceUrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m \u001b[49m\u001b[43mstatic_discovery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\introDS\\lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\introDS\\lib\\site-packages\\googleapiclient\\discovery.py:316\u001b[0m, in \u001b[0;36mbuild\u001b[1;34m(serviceName, version, http, discoveryServiceUrl, developerKey, model, requestBuilder, credentials, cache_discovery, cache, client_options, adc_cert_path, adc_key_path, num_retries, static_discovery, always_use_jwt_access)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# If discovery_http was created by this function, we are done with it\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# and can safely close it\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\introDS\\lib\\site-packages\\googleapiclient\\discovery.py:287\u001b[0m, in \u001b[0;36mbuild\u001b[1;34m(serviceName, version, http, discoveryServiceUrl, developerKey, model, requestBuilder, credentials, cache_discovery, cache, client_options, adc_cert_path, adc_key_path, num_retries, static_discovery, always_use_jwt_access)\u001b[0m\n\u001b[0;32m    284\u001b[0m requested_url \u001b[38;5;241m=\u001b[39m uritemplate\u001b[38;5;241m.\u001b[39mexpand(discovery_url, params)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43m_retrieve_discovery_doc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequested_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiscovery_http\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_discovery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserviceName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeveloperKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_discovery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_discovery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     service \u001b[38;5;241m=\u001b[39m build_from_document(\n\u001b[0;32m    299\u001b[0m         content,\n\u001b[0;32m    300\u001b[0m         base\u001b[38;5;241m=\u001b[39mdiscovery_url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m         always_use_jwt_access\u001b[38;5;241m=\u001b[39malways_use_jwt_access,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# exit if a service was created\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\introDS\\lib\\site-packages\\googleapiclient\\discovery.py:422\u001b[0m, in \u001b[0;36m_retrieve_discovery_doc\u001b[1;34m(url, http, cache_discovery, serviceName, version, cache, developerKey, num_retries, static_discovery)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# Execute this request with retries build into HttpRequest\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Note that it will already raise an error if we don't get a 2xx response\u001b[39;00m\n\u001b[0;32m    421\u001b[0m req \u001b[38;5;241m=\u001b[39m HttpRequest(http, HttpRequest\u001b[38;5;241m.\u001b[39mnull_postproc, actual_url)\n\u001b[1;32m--> 422\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    425\u001b[0m     content \u001b[38;5;241m=\u001b[39m content\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\introDS\\lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\introDS\\lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    936\u001b[0m     callback(resp)\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 400 when requesting https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1&key=insert_api_key returned \"API key not valid. Please pass a valid API key.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'commentanalyzer.googleapis.com'}}]\">"
     ]
    }
   ],
   "source": [
    " from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "API_KEY = 'insert_api_key'\n",
    "\n",
    "client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=API_KEY,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a5be115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Comments labeled as 'Toxic' with the word 'Bitch' in it: 117\n",
      "Number of Comments labeled as 'non-toxic' with the word 'Bitch' in it: 90\n"
     ]
    }
   ],
   "source": [
    "# sample_comments = pd.read_csv(\"Sample_labaled_data.csv\")\n",
    "sample_comments = pd.read_csv(\"B_only_dataset.csv\")\n",
    "\n",
    "# sample_comments.head()\n",
    "toxicity = list(sample_comments[\"toxic\"])\n",
    "comments = list(sample_comments[\"comment_text\"])\n",
    "\n",
    "toxic_comments = []\n",
    "neutral_comments = []\n",
    "\n",
    "for i in range(len(comments)):\n",
    "    toxic = toxicity[i]\n",
    "    comment = comments[i]\n",
    "    \n",
    "    if toxic == \"yes\":\n",
    "        toxic_comments.append(comment)\n",
    "    else:\n",
    "        neutral_comments.append(comment)\n",
    "\n",
    "       \n",
    "# print(neutral_comments)\n",
    "\n",
    "b_toxic_counter = 0\n",
    "for comment in toxic_comments:\n",
    "    if \"bitch\" in comment: \n",
    "        b_toxic_counter += 1\n",
    "        \n",
    "print(f\"Number of Comments labeled as 'Toxic' with the word 'Bitch' in it: {b_toxic_counter}\")\n",
    "\n",
    "b_neutral_counter = 0\n",
    "for comment in neutral_comments:\n",
    "    if \"bitch\" in comment: \n",
    "        b_neutral_counter += 1\n",
    "        \n",
    "print(f\"Number of Comments labeled as 'non-toxic' with the word 'Bitch' in it: {b_neutral_counter}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23886f01",
   "metadata": {},
   "source": [
    "# Results \n",
    "\n",
    "After analying this data set, it shows that for every non-toxic comment there is also a comment that is considered non toxic with the word bitch in it. There is almost a split difference in the type of labeling. It does contradict my hypothesis because there is a 12% difference of a comment being labeled toxic more often than not. A bigger sample size could always skew the data more.\n",
    "\n",
    "Some biases I think include what other words the comment is paired with. From manualy parsing the data, I saw that when bitch was accompanied by other sexist slurs or homophobic language it was flagged more. Another variable I saw was when a comment was in all caps it was labeled toxic even if it was just a random string of words.\n",
    "\n",
    "I think my results are the way they are because of the data set that I analized. It came pre-labeled so I do not know the paramaters of what \"toxic\" was for the labeler. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
